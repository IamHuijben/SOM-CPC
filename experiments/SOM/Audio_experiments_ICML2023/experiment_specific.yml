callbacks:
  PlotLoss:
    every_n_epochs: 5
    zero_class_is_nan_class: false
  SOMmap:
    checking_metric: null
    every_n_epochs: 20
    nr_nodes: 225
    zero_class_is_nan_class: false
  SaveModel:
    checking_metric: null
    every_n_epochs: 1
data:
  class: LibriSpeechFast
  crop_size: 0.01
  include_train_subjects: all
  include_val_subjects: all
  load_dir: Librispeech_preprocessed
  past_windows: 127
device:
  cuda: true
  gpu_idx: null
losses:
  SOM_loss:
    arguments:
      reduction: sum
    class: SOM_loss
    multiplier: 1.0
  commitment_loss:
    arguments:
      reduction: sum
    class: commitment_loss
    multiplier: 1.0
model:
  type: sequential
  checkpoint_path: null
  ARmodel:
    bias: true
    bidirectional: false
    checkpoint_path:  null
    class: ARmodule
    dropout: 0
    freeze: true
    input_size: 512
    num_stacked: 1
    output_size: 512
    type: gru
  encoder:
    activation:
      type: relu
    bias: true
    channels:
    - 512
    - 512
    - 512
    - 512
    - 512
    checkpoint_path: null
    class: ConvEncoder1D
    dilations: 1
    dropouts: null
    encode_windows_separately: false
    freeze: true
    input_dim:
    - 1
    - 160
    kernel_sizes:
      '0': 10
      '1': 8
      '2': 4
      '3': 4
      '4': 4
    out_activation:
      type: relu
    paddings:
      '0': 3
      '1': 2
      '2': 1
      '3': 1
      '4': 1
    poolings: null
    stacked_convs: 1
    strides:
      '0': 5
      '1': 4
      '2': 2
      '3': 2
      '4': 2
  permute:
    class: Permute
    permutation:
    - 2
    - 0
    - 1
  quantizer:
    GS_estimator: false
    GS_temperature:
      end: 1.0
      nr_epochs: 250
      start: 1.0
      type: linear
    ST_GS_estimator: false
    checkpoint_path: null
    class: SOMQuantizer
    freeze: false
    gaussian_neighbourhood:
      n_epochs: 250
      omit_center_weight: true
      sigma_end: 0.1
    som_nodes: 225
    transitions: false
    z_dim: 512
  select_last_element:
    axis: 0
    class: SelectLastElement
  module_order:
  - encoder
  - permute
  - ARmodel
  - select_last_element
  - quantizer
optimizer:
  lr: 0.01
  type: Adam
training:
  aggregate_pred_names:
  - all_codebook_idxs
  - all_z_cont
  data_shuffle: true
  n_epochs: 250
  random_seed: 1
  train_batch_size: 128
  val_batch_size: 128
